{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade transformers==4.44.2\n",
    "# !pip install lomo-optim\n",
    "# !pip install --upgrade accelerate\n",
    "# !pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f41a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     import accelerate\n",
    "# except Exception as e:\n",
    "#     !pip install -q -U transformers\n",
    "#     !pip install -q datasets accelerate\n",
    "#     !pip install -q lomo-optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93c9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0a0+81ea7a4\n",
      "4.44.2\n",
      "/home/work/patent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig, Trainer\n",
    "from transformers import DataCollatorWithPadding, EarlyStoppingCallback, TrainingArguments\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from trl import SFTTrainer\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6adeb4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/work/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token='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')\n",
    "# login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba8b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('./patent_total/data/ipc_title_abstract_claims/few_shot_train_data.pkl')\n",
    "# train_data = pd.read_pickle('./patent_total/data/ipc_title_abstract_claims/train_data.pkl')\n",
    "val_data = pd.read_pickle('./patent_total/data/ipc_title_abstract_claims/val_data.pkl')\n",
    "test_data = pd.read_pickle('./patent_total/data/ipc_title_abstract_claims/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2fbc23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88e966bb94e41af9e5e07712e935118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-9b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"google/gemma-2-9b\"\n",
    "# model_id = \"google/gemma-2-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# Set padding side to 'right'\n",
    "tokenizer.padding_side = 'right'\n",
    "#\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    num_labels=188,  # 188개의 클래스를 예측하도록 설정\n",
    "#     attn_implementation='eager',\n",
    ")\n",
    "# model.config.max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c5f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리: 텍스트 토크나이징 및 레이블 처리\n",
    "train_texts = train_data['combined_info'].tolist()  # train_data의 'combined_info' 열을 리스트로 변환\n",
    "train_labels = train_data['Mtext'].apply(lambda x: [int(i) for i in x]).tolist()  # 'Mtext'를 정수 리스트로 변환\n",
    "\n",
    "val_texts = val_data['combined_info'].tolist() # val_data 'combined_info' 열을 리스트로 변환\n",
    "val_labels = val_data['Mtext'].apply(lambda x: [int(i) for i in x]).tolist() # 'Mtext'를 정수 리스트로 변환\n",
    "\n",
    "test_texts = test_data['combined_info'].tolist()  # train_data의 'combined_info' 열을 리스트로 변환\n",
    "test_labels = test_data['Mtext'].apply(lambda x: [int(i) for i in x]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ccd6d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[     0,      0,      0,      2, 239060,  50691,  45980, 237199,  47555,\n",
      "         235265]])\n",
      "Attention Mask: tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Padding token ID: 0\n",
      "EOS token ID: 1\n"
     ]
    }
   ],
   "source": [
    "# 예시 입력\n",
    "input_text = \"테스트 문장입니다.\"\n",
    "\n",
    "# 토크나이징 및 패딩 처리 확인\n",
    "tokens = tokenizer(input_text, padding='max_length', max_length=10, return_tensors='pt')\n",
    "\n",
    "# 토큰화된 결과 출력\n",
    "print(f\"Input IDs: {tokens['input_ids']}\")\n",
    "print(f\"Attention Mask: {tokens['attention_mask']}\")\n",
    "print(f\"Padding token ID: {tokenizer.pad_token_id}\")\n",
    "print(f\"EOS token ID: {tokenizer.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62788d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F41G-007/00|F41G-003/08|F41G-007/34|F41G-009/00 지대지 유도탄의 궤적성형을 위한 가표적 선정 방법 및 이를 수행하는 장치 본 발명에 따른 지대지 유도탄의 궤적성형을 위한 가표적 선정 방법이 제공된다. 상기 방법은 가표적 선정 장치에 의해 수행되고, 상기 방법은, 상기 유도탄이 위치하는 제1 구간에 대하여 상기 유도탄에 대한 중기 고도궤적을 성형하는 중기 고도궤적 성형단계; 상기 제1 구간에 후속하는 천이구간으로 제2 구간에 대하여 상기 유도탄에 대한 천이 과정을 수행하는 천이 과정 수행 단계; 및 상기 제2 구간에 후속하는 제3 구간에 대하여 상기 유도탄에 대한 말기 고도궤적을 성형하는 말기 고도궤적 성형단계를 포함하여, 유도탄의 종말속도의 분산을 감소시킬 수 있다. 지대지 유도탄의 궤적성형을 위한 가표적 선정 방법에서, 상기 방법은 가표적 선정 장치에 의해 수행되고, 상기 방법은,상기 유도탄이 위치하는 제1 구간에 대하여 상기 유도탄에 대한 중기 고도궤적을 성형하는 중기 고도궤적 성형단계;상기 제1 구간에 후속하는 천이구간(d)으로 제2 구간에 대하여 상기 유도탄에 대한 천이 과정을 수행하는 천이 과정 수행 단계; 및상기 제2 구간에 후속하는 제3 구간에 대하여 상기 유도탄에 대한 말기 고도궤적을 성형하는 말기 고도궤적 성형단계를 포함하고,상기 제1 구간, 상기 제2 구간 및 상기 제3 구간은 발사점과 표적의 위치정보에 관한 정보를 이용하여 동적으로 결정되고,상기 제1 구간의 종점에 제1 가표적(AP1)을 배치하고, 상기 중기 고도궤적 성형단계와 상기 천이 과정 수행 단계를 반복하면서,상기 중기 고도궤적을 성형할 수 있는 상기 제1 구간이 증가하도록 상기 천이구간(d)을 감소시켜서, 저고도 비행 또는 고고도 비행을 통하여 상기 제1 가표적(AP1)으로 도달시점에서 상기 유도탄의 속도를 조절할 수 있는 영역을 증가시키고,상기 중기 고도궤적 성형단계와 상기 천이 과정 수행 단계에서,다수의 가표적인 AP1 내지 APn의 적중 여부 및 오차 정도에 기반하여 궤적을 변경하도록 제어하고,상기 유도탄의 비행 구간의 상기 다수의 가표적의 위치와 개수에 따라 복수의 중기 고도궤적 단계와 천이 단계를 반복하고, 표적까지의 사거리가 증가함에 따라 상기 중기 고도궤적 성형단계와 상기 천이 과정 수행 단계를 반복하면서 가표적의 개수를 증가시키는 것을 특징으로 하는, 가표적 선정 방법.지대지 유도탄의 궤적성형을 위한 가표적 선정 장치에서,발사점과 표적의 위치정보, 상기 유도탄의 질량, 추력, 추진제온도, 공력에 관한 유도탄 제원 정보를 수신하도록 구성된 인터페이스; 및상기 유도탄이 위치하는 제1 구간에 대하여 상기 유도탄에 대한 중기 고도궤적을 성형하고,상기 제1 구간에 후속하는 천이구간(d)으로 제2 구간에 대하여 상기 유도탄에 대한 천이 과정을 수행하고,상기 제2 구간에 후속하는 제3 구간에 대하여 상기 유도탄에 대한 말기 고도궤적을 성형하는 제어부를 포함하고,상기 제어부는, 상기 발사점과 표적의 위치정보에 관한 정보를 이용하여, 상기 제1 구간, 상기 제2 구간 및 상기 제3 구간을 동적으로 결정하고,상기 제1 구간의 종점에 제1 가표적(AP1)을 배치하고, 상기 중기 고도궤적을 성형하는 과정과 상기 천이 과정을 반복하면서,상기 중기 고도궤적을 성형할 수 있는 상기 제1 구간이 증가하도록 상기 천이구간(d)을 감소시켜서, 저고도 비행 또는 고고도 비행을 통하여 상기 제1 가표적(AP1)으로 도달시점에서 상기 유도탄의 속도를 조절할 수 있는 영역을 증가시키고,상기 중기 고도궤적을 성형하는 과정 및 상기 천이 과정에서,다수의 가표적인 AP1 내지 APn의 적중 여부 및 오차 정도에 기반하여 궤적을 변경하도록 제어하고,상기 유도탄의 비행 구간의 상기 다수의 가표적의 위치와 개수에 따라 복수의 중기 고도궤적 성형과 천이 과정을 반복하고, 표적까지의 사거리가 증가함에 따라 상기 중기 고도궤적을 성형하는 과정과 상기 천이 과정을 반복하면서 가표적의 개수를 증가시키는 것을 특징으로 하는, 가표적 선정 장치.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358f6372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 51]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae425ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이징\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors='pt') #4096, 1024\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512, return_tensors='pt') #4096, 1024\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512, return_tensors='pt') #4096, 1024\n",
    "\n",
    "# MultiLabelBinarizer를 사용해 Mtext를 one-hot 인코딩 (다중 라벨 처리)\n",
    "mlb = MultiLabelBinarizer(classes=range(188))\n",
    "train_labels = mlb.fit_transform(train_labels)\n",
    "val_labels = mlb.transform(val_labels)\n",
    "test_labels = mlb.transform(test_labels)\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class PatentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 학습 및 검증 데이터셋 준비\n",
    "train_dataset = PatentDataset(train_encodings, train_labels)\n",
    "val_dataset = PatentDataset(val_encodings, val_labels)\n",
    "test_dataset = PatentDataset(test_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65b25f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcf368ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d302943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encoding(num_tokens=4096, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
    "\n",
    "# # train_encodings에 어떤 키들이 있는지 확인\n",
    "# print(train_encodings.keys())\n",
    "\n",
    "# # 각 속성의 첫 번째 값을 확인\n",
    "# print(train_encodings['offsets'][0])# 스페셜 토큰 마스크 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7baef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 첫 번째 인스턴스의 모든 속성 확인\n",
    "# for key, value in train_encodings.items():\n",
    "#     print(f\"{key}: {value[0]}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2995e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassFocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(MultiClassFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (list, torch.Tensor)):\n",
    "                self.alpha = torch.tensor(self.alpha, device=inputs.device, dtype=inputs.dtype)\n",
    "                alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "            else:\n",
    "                alpha_factor = self.alpha\n",
    "            F_loss = alpha_factor * F_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "class CustomTrainer(SFTTrainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # MultiClass Focal Loss 적용\n",
    "        loss_fn = MultiClassFocalLoss(gamma=2.0, alpha=0.25)  # Focal Loss 설정\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9B, loss\n",
    "# Epoch\tTraining Loss\tValidation Loss\n",
    "# 1\t0.082900\t0.047412\n",
    "# 2\t0.072700\t0.043783\n",
    "# 3\t0.063500\t0.038974\n",
    "# 4\t0.053700\t0.034773\n",
    "# 5\t0.046800\t0.032850\n",
    "# 6\t0.039400\t0.030737\n",
    "# 7\t0.032900\t0.029718\n",
    "# 8\t0.027400\t0.029724\n",
    "# 9\t0.023400\t0.029951\n",
    "# 10\t0.019400\t0.030584\n",
    "\n",
    "# 2B, loss\n",
    "# TrainOutput(global_step=15020, training_loss=0.0631203863695363, \n",
    "# metrics={'train_runtime': 54824.0702, 'train_samples_per_second': 2.192, 'train_steps_per_second': 0.274, \n",
    "# 'total_flos': 1.4949465106415616e+18, 'train_loss': 0.0631203863695363, 'epoch': 20.0})\n",
    "# 20\t0.033600\t0.029522\n",
    "\n",
    "# optimizer\n",
    "# optim=\"lomo\", # 31.4GB @ bs=1\n",
    "# optim=\"adalomo\", # 36.8GB @ bs=4\n",
    "# optim=\"adafactor\", # CUDA OOM @ bs=1\n",
    "# optim=\"adamw_hf\", # CUDA OOM @ bs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e6c648d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/work/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/work/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 42:31:50, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.004401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.002230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.001759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:459: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2180/3437144486.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7500, training_loss=0.006259841245412827, metrics={'train_runtime': 153124.0906, 'train_samples_per_second': 0.785, 'train_steps_per_second': 0.049, 'total_flos': 6.13776441212928e+18, 'train_loss': 0.006259841245412827, 'epoch': 19.97336884154461})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train time - 41:44:18 (7500/7500) \n",
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=1024) # 분류 모델 적합 ,4096\n",
    "\n",
    "# Create Trainer objects that takes care of the process\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    args= TrainingArguments(\n",
    "        per_device_train_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=20,\n",
    "        learning_rate=1e-4,\n",
    "        bf16=True,\n",
    "        logging_steps=100,\n",
    "        eval_strategy=\"epoch\",  # 평가 전략을 \"steps\"로 설정\n",
    "        save_strategy=\"epoch\",  # 매 epoch 마다 모델 저장\n",
    "#         eval_steps=10,  # 50 스텝마다 평가\n",
    "        metric_for_best_model='eval_loss',\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"adalomo\", # \"paged_adamw_8bit, \"adalomo\",\n",
    "        max_grad_norm=1.0,  # Apply gradient clipping\n",
    "        gradient_checkpointing = True\n",
    "    ),\n",
    "    max_seq_length=512, #1024,  # \n",
    "    data_collator=data_collator,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28f13773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7f9a674db34929a2d2ce1cf5d614f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd81d3d7761a4de7b7f8020de4689262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2758e532d33b4f1893fa3f6dd5941083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb88dee2aba490ea274873e6ac883ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7b2de38e0246dc85b02e9684facf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 500 thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/cc/64/cc6485fee34feea2ad93cebbbef8ffda3e832c683d6cbb8ed44a3af7df417258/c94e7df0941c6c158cbf10072b4b17813702419bdd6364219fb54d1c2dda5a1e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20241003%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241003T123435Z&X-Amz-Expires=86400&X-Amz-Signature=ab648de9e313e4393074d8c552bd9c562abc3872a1db32a617fe71de1e0f82ae&X-Amz-SignedHeaders=host&partNumber=2&uploadId=UC3f6N4HXKJiFK9zKI6rxMaUVMhrC8726diD59xEM5ImyYR15zIdXhFkqBg6IXi.VGuilHzCwssSrYVVvOzOgeS9tEXUqbxB6j0Sjexf0AemQuwFfNBe0q5VxFhyEwEg&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/3won/fft-koalpaca-gemma2-9b-20epoch/commit/c83443ba03ba77a9d20d714449222634640bafc7', commit_message='Upload Gemma2ForSequenceClassification', commit_description='', oid='c83443ba03ba77a9d20d714449222634640bafc7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/3won/fft-koalpaca-gemma2-9b-20epoch', endpoint='https://huggingface.co', repo_type='model', repo_id='3won/fft-koalpaca-gemma2-9b-20epoch'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# huggingface model push\n",
    "model.push_to_hub('3won/fft-koalpaca-gemma2-9b-20epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2178f8",
   "metadata": {},
   "source": [
    "## best model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "330d036a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12c3a7b65ec49559f04f22b1ad173c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_directory = \"/home/work/patent/outputs/checkpoint-4506\"\n",
    "# Load the tokenizer and the model from the directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16535e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f29775e1dfb4be69aab1e447711de1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e0cbde6bc94790920d478804d0ee18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 8 LFS files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6138308fc50416d926eb5f1d259d2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca8a5e789464225a1b560b0813dbc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaad5f346f2404e9110e27f64688fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c055b8628e4f5f9daa00095068c492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/2.38G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5a509687404286a0e951fcde9a5997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a10a8ed0014a85b7abdae4ceec7b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/4.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6705e9938454d7a8d4d72280c2b53b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/3won/KoSCoST-gemma2-9b-12epoch/commit/cb596cd0cfe78e7643311468b63f86e4ceecc242', commit_message='Upload Gemma2ForSequenceClassification', commit_description='', oid='cb596cd0cfe78e7643311468b63f86e4ceecc242', pr_url=None, repo_url=RepoUrl('https://huggingface.co/3won/KoSCoST-gemma2-9b-12epoch', endpoint='https://huggingface.co', repo_type='model', repo_id='3won/KoSCoST-gemma2-9b-12epoch'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# huggingface model push\n",
    "model.push_to_hub('3won/KoSCoST-gemma2-9b-12epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe6abd",
   "metadata": {},
   "source": [
    "## 개별값 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "985db7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "         0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "         0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "         0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "         1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "         1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "         0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "         1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1]],\n",
      "       device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.half() # FP16 사용\n",
    "\n",
    "# 새로운 데이터에 대한 예측\n",
    "test_encodings = tokenizer(train_texts[0], truncation=True, padding=True, max_length=1024, return_tensors='pt')\n",
    "\n",
    "# Move the encodings to the same device as the model\n",
    "test_encodings = {key: val.to(device) for key, val in test_encodings.items()}\n",
    "\n",
    "# 캐시 활성화 및 no_grad 설정\n",
    "model.config.use_cache = True\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        outputs = model(**test_encodings)\n",
    "\n",
    "# 출력값을 소프트맥스나 시그모이드 함수로 변환하여 다중 라벨 예측 수행\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(outputs.logits)\n",
    "probs\n",
    "# 0.5를 기준으로 여러 클래스를 선택 (multi-label classification)\n",
    "predictions = (probs > 0.5).int()\n",
    "\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2 (NGC 23.11/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
